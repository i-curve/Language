* [1. 数据缺失](#1)
* [2. 数据编码方法](#2)
* [3. 数据预处理](#3)
* [4. 数据整合](#4)
* [5.交叉验证](#5)

**<a id='1'>1. 数据缺失</a>**

1. from sklearn.impute import SimpleImpute
2. 扩展impute,添加一个标记是否缺失的列值,并进行impute填充

**<a id='2'>2. 数据编码方法</a>**

- **Label-Encoding**:

  from sklearn.preprocessing import LabelEncoder

  依据类别是有序的,给定一个唯一值

- **one-hot编码**:根据数据种类的个数转换为多少维的空间,除了能够表示自己的哪一位数值为1,其他的数值都是0. 实现方法:

  from sklearn.preprocessing import OneHotEncoder

  一般创建的时候传递参数handle_unknown='ignore',sparse=False

  方法.fit() ,  .fit_transform(),  .transform()

  <font size=2>***神经网络*** </font>:from keras.utils.np_utils import to_categorical  

**<a id='3'>3. 数据预处理</a>**

1. StandardScaler():标准化

   from skleran.preprocessing import StandardScaler()

   $X$ = $(x-u)\over{s}$ :转换为均值为0,方差为1的正态分布

2. MinMaxScaler():归一化
   from sklearn.preprocessing import MinMaxScaler(feature_range=(0,1))

   $X$ = $(x-x_{min})\over{X^{max}-X_{min}}$ :把所有特征都等比例的缩放到0\~1,-1\~1之间

3. Normalizer():正则化

   $X=$ $x\over{(x_1^2+x_2^2+...+x_n^2)^{1/2}} $ :对每个样本进行处理,不是特征

**<a id='4'>4. 数据整合(管道)</a>**

整合: from sklearn.compose import ColumnTransformer

preprocessor = ColumnTransformer(transformers=[('num',num_tran,num_cols),('cat',cat_tran,cat_cols)])

管道: from sklearn.pipeline import Pipeline

my_pipeline = Pipeline(step=[('preprocessing',pre),('model',model)])

**<a id='5'>5. 交叉验证</a>**

1. cross_val_score(my_pipeline,X,y,cv=3,scoring=""):标准交叉验证

   下面的均是修改cv为函数

2. 分层交叉验证:StratifiedKFold(n_splits=3,shuffle=True,random_state=0)

   在每一折中都保持折原始数据中各个类别的比例关系

3. 留一法:LeaveOneOut()

   针对小样本